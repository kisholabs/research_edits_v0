
@article{morland_steady_1980,
	title = {Steady {Motion} of {Ice} {Sheets}},
	volume = {25},
	issn = {0022-1430, 1727-5652},
	url = {https://www.cambridge.org/core/journals/journal-of-glaciology/article/steady-motion-of-ice-sheets/37808680C685BE8C5E43B92238C562C8},
	doi = {10.3189/S0022143000010467},
	abstract = {Steady plane flow under gravity of a symmetric ice sheet resting on a horizontal rigid bed, subject to surface accumulation and ablation, basal drainage, and basal sliding according to a shear-traction-velocity power law, is treated. The surface accumulation is taken to depend on height, and the drainage and sliding coefficient also depend on the height of overlying ice. The ice is described as a general non-linearly viscous incompressible fluid, with illustrations presented for Glen’s power law, the polynomial law of Colbeck and Evans, and a Newtonian fluid. Uniform temperature is assumed so that effects of a realistic temperature distribution on the ice response are not taken into account. In dimensionless variables a small paramter ν occurs, but the ν = 0 solution corresponds to an unbounded sheet of uniform depth. To obtain a bounded sheet, a horizontal coordinate scaling by a small factor ε(ν) is required, so that the aspect ratio ε of a steady ice sheet is determined by the ice properties, accumulation magnitude, and the magnitude of the central thickness. A perturbation expansion in ε gives simple leading-order terms for the stress and velocity components, and generates a first order non-linear differential equation for the free-surface slope, which is then integrated to determine the profile. The non-linear differential equation can be solved explicitly for a linear sliding law in the Newtonian case. For the general law it is shown that the leading-order approximation is valid both at the margin and in the central zone provided that the power and coefficient in the sliding law satisfy certain restrictions., RésuméOn traite de l’écoulement permanent plan sous l’effet de la gravité d’une calotte glaciaire symétrique reposant sur un lit horizontal rigide sous l’influence de l’accumulation et de l’ablation de surface avec évacuation au fond et glissement sur le lit selon une loi exponentielle vitesse/cisaillement. On admet que la surface d’accumulation depénd de la hauteur, les coefficients d’écoulement et de glissement dépendent aussi de la hauteur de la glace susjacente. La glace est considérée comme un fluide incompressible, à viscosité non linéaire, avec des exemples présentés suivant la loi exponentielle de Glen, la loi polynomiale de Colbeck et Evans et la loi de Newton. On admet une température uniforme de sorte que les effets de la distribution réelle des témperatures sur le comportement de la glace ne sont pas pris en compte. En variables sans dimensions un petit paramètre ν intervient, mais la solution ν = 0 correspond à une calotte non limitée d’épaisseur uniforme. Pour obtenir une calotte finie, il faut pondérer les coordonnées horizontales par un petit facteur ε(ν) de sorte que le rapport de relief ϵ d’une calotte en état d’équilibre est déterminé par les propriétés de la glace, l’importance de l’accumulation et l’ordre de grandeur de l’épaisseur au centre. Une perturbation par expansion de ε donne des modifications simples des termes réglant les composantes de contrainte et de vitesse, et entraîne une équation différentielle non linéaire de premier ordre pour la pente de la surface libre, qu’on peut alors intégrer pour déterminer le profil, L’équation différentielle linéaire peut être résolue explicitement pour une loi linéaire de glissement dans le cas de l’écoulement Newtonien. Pour la loi générale, on montre que l’approximation de premier ordre est valable à la fois sur la zone de bordure et au centre pourvu que l’exposant et le coefficient de la loi de glissement satisfassent certaines conditions., ZusammenfassungEs wird der stationäre, ebene Fluss unter Schwer-kraft eines symetrischen Eisschildes behandelt, der auf einem horizontalen starren Bett auf liegt, an seiner Oberfläche Akkumulation und Ablation erfährt, ein Abflusssystem am Untergrund besitzt und dort nach einem Exponentialgesetz zwischen Scherspannung und Geschwindigkek gleitct. Für die Akkumulation an der Oberfläche wird Höhenabhängigkeit angenommen; auch der Abfluss und der Gleitkoeffizient sollen von der Höhe des überlagernden Eises abhängen. Das Eis gilt als eine im allgemeinen nicht linear viskose, inkompressible Flüissigkeit, wobei Beispiele für Glen’s Exponentialgesetz, für das Polynomgesetz von Colbeck und Evans und Für eine Newton’sche Flüssigkeit herangezogen werden. Es wird gleichförmige Temperatur angenommen, weshalb die Einflüsse einer tatsächlichen Temperaturverteilung auf das Verhalten des Eises nicht berücksichtigt werden. Bei dimensionslosen Variablen tritt ein kleiner Parameter ν auf, doch entspricht die Lösung für ν = 0 einem unbegrenzten Eisschiid konstanter Dicke. Für einen begrenzten Eisschild wird eine horizontale Koordinatenbeziffcrung mit einem kleinen Faktor ε(ν) benötigt, so dass das Verhältnis ε eines stationären Eisschildes durch die Eigenschaften des Eises, die Grösse der Akkumulation und die Dicke im Zentrum bestimmt wird. Eine Störungsexpansion in ε gibt einfache Richtwertausdrücke für die Komponenten der Spannung und Geschwindigkeit und führt zu einer nichtlinearen Differentialgleichung 1. Ordnung für die Neigung der freien Oberfläche, deren Integration das Profil liefert; sie kann explizit für ein lineares Gleitgesetz im Newton’schen Fall gelöst werden. Für den allgemeinen Fall wird gezeigt, dass die Richtwertnäherung sowohl am Rand wie im Zentrum gilt, sofern die Potenz und der Koeffizient im Gleitgesetz bestimmten Einschränkungen genügen.},
	language = {en},
	number = {92},
	urldate = {2022-09-14},
	journal = {Journal of Glaciology},
	author = {Morland, L. W. and Johnson, I. R.},
	year = {1980},
	note = {Publisher: Cambridge University Press},
	pages = {229--246},
}

@article{revill_value_2019,
	title = {The {Value} of {Sentinel}-2 {Spectral} {Bands} for the {Assessment} of {Winter} {Wheat} {Growth} and {Development}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/11/17/2050},
	doi = {10.3390/rs11172050},
	abstract = {Leaf Area Index (LAI) and chlorophyll content are strongly related to plant development and productivity. Spatial and temporal estimates of these variables are essential for efficient and precise crop management. The availability of open-access data from the European Space Agency’s (ESA) Sentinel-2 satellite—delivering global coverage with an average 5-day revisit frequency at a spatial resolution of up to 10 metres—could provide estimates of these variables at unprecedented (i.e., sub-field) resolution. Using synthetic data, past research has demonstrated the potential of Sentinel-2 for estimating crop variables. Nonetheless, research involving a robust analysis of the Sentinel-2 bands for supporting agricultural applications is limited. We evaluated the potential of Sentinel-2 data for retrieving winter wheat LAI, leaf chlorophyll content (LCC) and canopy chlorophyll content (CCC). In coordination with destructive and non-destructive ground measurements, we acquired multispectral data from an Unmanned Aerial Vehicle (UAV)-mounted sensor measuring key Sentinel-2 spectral bands (443 to 865 nm). We applied Gaussian processes regression (GPR) machine learning to determine the most informative Sentinel-2 bands for retrieving each of the variables. We further evaluated the GPR model performance when propagating observation uncertainty. When applying the best-performing GPR models without propagating uncertainty, the retrievals had a high agreement with ground measurements—the mean R2 and normalised root-mean-square error (NRMSE) were 0.89 and 8.8\%, respectively. When propagating uncertainty, the mean R2 and NRMSE were 0.82 and 11.9\%, respectively. When accounting for measurement uncertainty in the estimation of LAI and CCC, the number of most informative Sentinel-2 bands was reduced from four to only two—the red-edge (705 nm) and near-infrared (865 nm) bands. This research demonstrates the value of the Sentinel-2 spectral characteristics for retrieving critical variables that can support more sustainable crop management practices.},
	language = {en},
	number = {17},
	urldate = {2022-08-01},
	journal = {Remote Sensing},
	author = {Revill, Andrew and Florence, Anna and MacArthur, Alasdair and Hoad, Stephen P. and Rees, Robert M. and Williams, Mathew},
	month = jan,
	year = {2019},
	note = {Number: 17
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Gaussian processes regression, Sentinel-2 spectral analysis, machine learning, red-edge band, vegetation parameter retrieval, winter wheat assessment},
	pages = {2050},
}

@misc{noauthor_global_nodate,
	title = {Global {Energy} {Review}: {CO2} {Emissions} in 2021 – {Analysis}},
	shorttitle = {Global {Energy} {Review}},
	url = {https://www.iea.org/reports/global-energy-review-co2-emissions-in-2021-2},
	abstract = {Global Energy Review: CO2 Emissions in 2021 - Analysis and key findings. A report by the International Energy Agency.},
	language = {en-GB},
	urldate = {2022-07-31},
	journal = {IEA},
}

@book{intergovernmental_panel_on_climate_change_climate_2014,
	address = {New York, NY},
	title = {Climate change 2014: mitigation of climate change: {Working} {Group} {III} contribution to the {Fifth} {Assessment} {Report} of the {Intergovernmental} {Panel} on {Climate} {Change}},
	isbn = {978-1-107-05821-7 978-1-107-65481-5},
	shorttitle = {Climate change 2014},
	language = {en},
	publisher = {Cambridge University Press},
	editor = {Intergovernmental Panel on Climate Change and Edenhofer, Ottmar},
	year = {2014},
	note = {OCLC: ocn892580682},
	keywords = {Climate change mitigation, Climatic changes, Global environmental change, Government policy, International cooperation},
}

@article{drusch_sentinel-2_2012,
	series = {The {Sentinel} {Missions} - {New} {Opportunities} for {Science}},
	title = {Sentinel-2: {ESA}'s {Optical} {High}-{Resolution} {Mission} for {GMES} {Operational} {Services}},
	volume = {120},
	issn = {0034-4257},
	shorttitle = {Sentinel-2},
	url = {https://www.sciencedirect.com/science/article/pii/S0034425712000636},
	doi = {10.1016/j.rse.2011.11.026},
	abstract = {Global Monitoring for Environment and Security (GMES) is a joint initiative of the European Commission (EC) and the European Space Agency (ESA), designed to establish a European capacity for the provision and use of operational monitoring information for environment and security applications. ESA's role in GMES is to provide the definition and the development of the space- and ground-related system elements. GMES Sentinel-2 mission provides continuity to services relying on multi-spectral high-resolution optical observations over global terrestrial surfaces. The key mission objectives for Sentinel-2 are: (1) To provide systematic global acquisitions of high-resolution multi-spectral imagery with a high revisit frequency, (2) to provide enhanced continuity of multi-spectral imagery provided by the SPOT (Satellite Pour l'Observation de la Terre) series of satellites, and (3) to provide observations for the next generation of operational products such as land-cover maps, land change detection maps, and geophysical variables. Consequently, Sentinel-2 will directly contribute to the Land Monitoring, Emergency Response, and Security services. The corresponding user requirements have driven the design toward a dependable multi-spectral Earth-observation system featuring the Multi Spectral Instrument (MSI) with 13 spectral bands spanning from the visible and the near infrared to the short wave infrared. The spatial resolution varies from 10m to 60m depending on the spectral band with a 290km field of view. This unique combination of high spatial resolution, wide field of view and spectral coverage will represent a major step forward compared to current multi-spectral missions. The mission foresees a series of satellites, each having a 7.25-year lifetime over a 15-year period starting with the launch of Sentinel-2A foreseen in 2013. During full operations two identical satellites will be maintained in the same orbit with a phase delay of 180° providing a revisit time of five days at the equator. This paper provides an overview of the GMES Sentinel-2 mission including a technical system concept overview, image quality, Level 1 data processing and operational applications.},
	language = {en},
	urldate = {2022-07-30},
	journal = {Remote Sensing of Environment},
	author = {Drusch, M. and Del Bello, U. and Carlier, S. and Colin, O. and Fernandez, V. and Gascon, F. and Hoersch, B. and Isola, C. and Laberinti, P. and Martimort, P. and Meygret, A. and Spoto, F. and Sy, O. and Marchese, F. and Bargellini, P.},
	month = may,
	year = {2012},
	keywords = {GMES, Land cover classification, Optical multi-spectral instrument, Remote sensing, Sentinel-2},
	pages = {25--36},
}

@misc{noauthor_xgboost_nodate,
	title = {{XGBoost} {\textbar} {Proceedings} of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	url = {https://dl.acm.org/doi/abs/10.1145/2939672.2939785},
	urldate = {2022-07-30},
}

@misc{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2022-07-30},
	publisher = {arXiv},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv:1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{szegedy_rethinking_2015,
	title = {Rethinking the {Inception} {Architecture} for {Computer} {Vision}},
	url = {http://arxiv.org/abs/1512.00567},
	abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5\% top-5 error on the validation set (3.6\% error on the test set) and 17.3\% top-1 error on the validation set.},
	urldate = {2022-07-30},
	publisher = {arXiv},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
	month = dec,
	year = {2015},
	note = {arXiv:1512.00567 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2022-07-30},
	publisher = {arXiv},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv:1512.03385 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{raghuvanshi_carbon_2006,
	title = {Carbon dioxide emissions from coal based power generation in {India}},
	volume = {47},
	issn = {0196-8904},
	url = {https://www.sciencedirect.com/science/article/pii/S0196890405001214},
	doi = {10.1016/j.enconman.2005.05.007},
	abstract = {Coal is the major fossil fuel used in industrial units and power plants for power generation in India. The carbon dioxide emitted as a product of combustion of coal (fossil fuels) is currently responsible for over 60\% of the enhanced greenhouse effect. The present communication is an attempt to provide a brief investigation of CO2 emission from coal based power generation in India. Energy indicators, trends in energy consumption and carbon dioxide emissions have been thoroughly investigated. Methodology for analysis of carbon emissions and possible sinks is also provided.},
	language = {en},
	number = {4},
	urldate = {2022-07-30},
	journal = {Energy Conversion and Management},
	author = {Raghuvanshi, Shiv Pratap and Chandra, Avinash and Raghav, Ashok Kumar},
	month = mar,
	year = {2006},
	keywords = {CO emission, CO mitigation, Coal, Combustion, Energy consumption, Sinks},
	pages = {427--441},
}

@article{noauthor_greenhouse_nodate,
	title = {Greenhouse {Gas} {Reporting} {Program}: {Industrial} {Profile}: {Power} {Plants} {Sector}},
	language = {en},
	pages = {16},
}

@article{vohra_global_2021,
	title = {Global mortality from outdoor fine particle pollution generated by fossil fuel combustion: {Results} from {GEOS}-{Chem}},
	volume = {195},
	issn = {0013-9351},
	shorttitle = {Global mortality from outdoor fine particle pollution generated by fossil fuel combustion},
	url = {https://www.sciencedirect.com/science/article/pii/S0013935121000487},
	doi = {10.1016/j.envres.2021.110754},
	abstract = {The burning of fossil fuels – especially coal, petrol, and diesel – is a major source of airborne fine particulate matter (PM2.5), and a key contributor to the global burden of mortality and disease. Previous risk assessments have examined the health response to total PM2.5, not just PM2.5 from fossil fuel combustion, and have used a concentration-response function with limited support from the literature and data at both high and low concentrations. This assessment examines mortality associated with PM2.5 from only fossil fuel combustion, making use of a recent meta-analysis of newer studies with a wider range of exposure. We also estimated mortality due to lower respiratory infections (LRI) among children under the age of five in the Americas and Europe, regions for which we have reliable data on the relative risk of this health outcome from PM2.5 exposure. We used the chemical transport model GEOS-Chem to estimate global exposure levels to fossil-fuel related PM2.5 in 2012. Relative risks of mortality were modeled using functions that link long-term exposure to PM2.5 and mortality, incorporating nonlinearity in the concentration response. We estimate a global total of 10.2 (95\% CI: −47.1 to 17.0) million premature deaths annually attributable to the fossil-fuel component of PM2.5. The greatest mortality impact is estimated over regions with substantial fossil fuel related PM2.5, notably China (3.9 million), India (2.5 million) and parts of eastern US, Europe and Southeast Asia. The estimate for China predates substantial decline in fossil fuel emissions and decreases to 2.4 million premature deaths due to 43.7\% reduction in fossil fuel PM2.5 from 2012 to 2018 bringing the global total to 8.7 (95\% CI: −1.8 to 14.0) million premature deaths. We also estimated excess annual deaths due to LRI in children (0–4 years old) of 876 in North America, 747 in South America, and 605 in Europe. This study demonstrates that the fossil fuel component of PM2.5 contributes a large mortality burden. The steeper concentration-response function slope at lower concentrations leads to larger estimates than previously found in Europe and North America, and the slower drop-off in slope at higher concentrations results in larger estimates in Asia. Fossil fuel combustion can be more readily controlled than other sources and precursors of PM2.5 such as dust or wildfire smoke, so this is a clear message to policymakers and stakeholders to further incentivize a shift to clean sources of energy.},
	language = {en},
	urldate = {2022-07-30},
	journal = {Environmental Research},
	author = {Vohra, Karn and Vodonos, Alina and Schwartz, Joel and Marais, Eloise A. and Sulprizio, Melissa P. and Mickley, Loretta J.},
	month = apr,
	year = {2021},
	keywords = {Fossil fuel, Health impact assessment, Mortality, Particulate matter},
	pages = {110754},
}

@inproceedings{chen_xgboost_2016,
	address = {New York, NY, USA},
	series = {{KDD} '16},
	title = {{XGBoost}: {A} {Scalable} {Tree} {Boosting} {System}},
	isbn = {978-1-4503-4232-2},
	shorttitle = {{XGBoost}},
	url = {https://doi.org/10.1145/2939672.2939785},
	doi = {10.1145/2939672.2939785},
	abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
	urldate = {2022-07-29},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Tianqi and Guestrin, Carlos},
	month = aug,
	year = {2016},
	keywords = {large-scale machine learning},
	pages = {785--794},
}

@misc{simonyan_very_2015-1,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2022-07-30},
	publisher = {arXiv},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv:1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{long_fully_2015,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1411.4038},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20\% relative improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes one third of a second for a typical image.},
	urldate = {2022-07-30},
	publisher = {arXiv},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	month = mar,
	year = {2015},
	note = {arXiv:1411.4038 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{lines_review_1984,
	title = {A {Review} of {Least}-{Squares} {Inversion} and {Its} {Application} to {Geophysical} {Problems}*},
	volume = {32},
	issn = {1365-2478},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2478.1984.tb00726.x},
	doi = {10.1111/j.1365-2478.1984.tb00726.x},
	abstract = {Geophysical inversion involves the estimation of the parameters of a postulated earth model from a set of observations. Since the associated model responses can be nonlinear functions of the model parameters, nonlinear least-squares techniques prove to be useful for performing the inversion. A common type of inversion applies iterative damped linear least squares through use of the Marquardt-Levenberg method. Traditionally, this method has been implemented by solving the associated normal equations in conventional ways. However, Singular Value Decomposition (SVD) produces significant improvements in computational precision when applied to the same system of normal equations. Iterative least-squares modeling finds application in a wide variety of geophysical problems. Two examples illustrate the approach: (1) seismic wavelet deconvolution, and (2) the location of a buried wedge from surface gravity data. More generally, nonlinear least-squares inversion can be used to estimate earth models for any set of geophysical observations for which an appropriate mathematical description is available.},
	language = {en},
	number = {2},
	urldate = {2022-07-28},
	journal = {Geophysical Prospecting},
	author = {Lines, L.r. and Trei℡, S.},
	year = {1984},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2478.1984.tb00726.x},
	pages = {159--186},
}

@article{pattyn_greenland_2018,
	title = {The {Greenland} and {Antarctic} ice sheets under 1.5 °{C} global warming},
	volume = {8},
	issn = {1758-678X, 1758-6798},
	url = {http://www.nature.com/articles/s41558-018-0305-8},
	doi = {10.1038/s41558-018-0305-8},
	language = {en},
	number = {12},
	urldate = {2022-07-28},
	journal = {Nature Climate Change},
	author = {Pattyn, Frank and Ritz, Catherine and Hanna, Edward and Asay-Davis, Xylar and DeConto, Rob and Durand, Gaël and Favier, Lionel and Fettweis, Xavier and Goelzer, Heiko and Golledge, Nicholas R. and Kuipers Munneke, Peter and Lenaerts, Jan T. M. and Nowicki, Sophie and Payne, Antony J. and Robinson, Alexander and Seroussi, Hélène and Trusel, Luke D. and van den Broeke, Michiel},
	month = dec,
	year = {2018},
	pages = {1053--1061},
}

@article{the_imbie_team_mass_2020,
	title = {Mass balance of the {Greenland} {Ice} {Sheet} from 1992 to 2018},
	volume = {579},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/s41586-019-1855-2},
	doi = {10.1038/s41586-019-1855-2},
	language = {en},
	number = {7798},
	urldate = {2022-07-28},
	journal = {Nature},
	author = {{The IMBIE Team}},
	month = mar,
	year = {2020},
	pages = {233--239},
}

@article{finzel_surface_2015,
	title = {Surface motions and intraplate continental deformation in {Alaska} driven by mantle flow},
	volume = {42},
	issn = {1944-8007},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2015GL063987},
	doi = {10.1002/2015GL063987},
	abstract = {The degree to which the lithosphere and mantle are coupled and contribute to surface deformation beneath continental regions remains a fundamental question in the field of geodynamics. Here we use a new approach with a surface deformation field constrained by GPS, geologic, and seismicity data, together with a lithospheric geodynamic model, to solve for tractions inferred to be generated by mantle convection that (1) drive extension within interior Alaska generating southward directed surface motions toward the southern convergent plate boundary, (2) result in accommodation of the relative motions between the Pacific and North America in a comparatively small zone near the plate boundary, and (3) generate the observed convergence within the North American plate interior in the Mackenzie mountains in northwestern Canada. The evidence for deeper mantle influence on surface deformation beneath a continental region suggests that this mechanism may be an important contributing driver to continental plate assemblage and breakup.},
	language = {en},
	number = {11},
	urldate = {2022-07-27},
	journal = {Geophysical Research Letters},
	author = {Finzel, Emily S. and Flesch, Lucy M. and Ridgway, Kenneth D. and Holt, William E. and Ghosh, Attreyee},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/2015GL063987},
	keywords = {Alaska, continental deformation, geodynamics, mantle tractions},
	pages = {4350--4358},
}

@misc{noauthor_surface_nodate,
	title = {Surface motions and intraplate continental deformation in {Alaska} driven by mantle flow - {Finzel} - 2015 - {Geophysical} {Research} {Letters} - {Wiley} {Online} {Library}},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2015GL063987},
	urldate = {2022-07-27},
}

@article{liao_ionospheric_2018,
	title = {Ionospheric correction of {InSAR} data for accurate ice velocity measurement at polar regions},
	volume = {209},
	issn = {0034-4257},
	url = {https://www.sciencedirect.com/science/article/pii/S0034425718300580},
	doi = {10.1016/j.rse.2018.02.048},
	abstract = {Interferometric synthetic aperture radar (InSAR) has become an essential tool for measuring ice sheet velocity in the Polar Regions. At low radar frequencies, e.g. L-band (1.2 GHz) but also at higher frequency, e.g. C-band (5.6 GHz), the ionosphere has been documented to be an important source of noise in these data. In this paper, we employ a split-spectrum technique and investigate its performance for correcting ionospheric effects in InSAR-based ice velocity measurements in Greenland and Antarctica. Three case studies using ALOS PALSAR data are used to assess the performance of the split spectrum technique for ionosphere correction over a range of environmental parameters. We employ several approaches to evaluate the results, including visual inspection, profile analysis, comparison of experimental and theoretic errors, comparison with reference data from other sources, generation of double difference interferograms, and analysis of time series of multi-temporal data. Our experiments show that ionospheric distortions are observed regularly, and in our analyzed Greenland dataset and Antarctic dataset the ionospheric noise reaches 14 m/yr and 10 m/yr, respectively, which exceeds the signal associated with ice motion. Our analysis using several different approaches demonstrates that the split-spectrum technique provides an effective correction. The split spectrum technique is also found to be superior to currently used approaches such as baseline fitting and multi-temporal averaging. The noise level is reduced by a factor of 70\% in Greenland test areas and 90\% in Antarctic test areas.},
	language = {en},
	urldate = {2022-07-27},
	journal = {Remote Sensing of Environment},
	author = {Liao, Heming and Meyer, Franz J. and Scheuchl, Bernd and Mouginot, Jeremie and Joughin, Ian and Rignot, Eric},
	month = may,
	year = {2018},
	keywords = {Data stacking, Ice velocity, Ionosphere correction, Ionosphere effect, Range split spectrum, SAR interferometry, Synthetic aperture radar},
	pages = {166--180},
}

@misc{noauthor_greenland_nodate,
	title = {Greenland {Ice} {Loss} 2002-2021},
	url = {https://grace.jpl.nasa.gov/resources/30/greenland-ice-loss-2002-2021},
	abstract = {Research based on GRACE observations indicates that between 2002 and 2021, Greenland shed approximately 280 gigatons of ice per year.},
	language = {en},
	urldate = {2022-07-27},
	journal = {GRACE Tellus},
}

@book{stocker_climate_2013,
	address = {s.l.},
	title = {Climate change 2013: the physical science basis: summary for policymakers, a report of working group {I} of the {IPCC}: technical summary, a report accepted by working group {I} of the {IPCC} but not approved in detail: and frequently asked questions: part of the working group {I} contribution to the fifth assessment report of the intergovernmental panel on climate change},
	isbn = {978-92-9169-138-8},
	shorttitle = {Climate change 2013},
	language = {en},
	publisher = {WMO, UNEP},
	editor = {Stocker, Thomas and Qin, Dahe},
	year = {2013},
}

@article{king_dynamic_2020,
	title = {Dynamic ice loss from the {Greenland} {Ice} {Sheet} driven by sustained glacier retreat},
	volume = {1},
	copyright = {2020 The Author(s)},
	issn = {2662-4435},
	url = {https://www.nature.com/articles/s43247-020-0001-2},
	doi = {10.1038/s43247-020-0001-2},
	abstract = {The Greenland Ice Sheet is losing mass at accelerated rates in the 21st century, making it the largest single contributor to rising sea levels. Faster flow of outlet glaciers has substantially contributed to this loss, with the cause of speedup, and potential for future change, uncertain. Here we combine more than three decades of remotely sensed observational products of outlet glacier velocity, elevation, and front position changes over the full ice sheet. We compare decadal variability in discharge and calving front position and find that increased glacier discharge was due almost entirely to the retreat of glacier fronts, rather than inland ice sheet processes, with a remarkably consistent speedup of 4–5\% per km of retreat across the ice sheet. We show that widespread retreat between 2000 and 2005 resulted in a step-increase in discharge and a switch to a new dynamic state of sustained mass loss that would persist even under a decline in surface melt.},
	language = {en},
	number = {1},
	urldate = {2022-07-27},
	journal = {Communications Earth \& Environment},
	author = {King, Michalea D. and Howat, Ian M. and Candela, Salvatore G. and Noh, Myoung J. and Jeong, Seongsu and Noël, Brice P. Y. and van den Broeke, Michiel R. and Wouters, Bert and Negrete, Adelaide},
	month = aug,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Cryospheric science, Planetary science},
	pages = {1--7},
}

@misc{noauthor_greenland_nodate-1,
	title = {Greenland, {Antarctica} {Melting} {Six} {Times} {Faster} {Than} in the 1990s},
	url = {https://climate.nasa.gov/news/2958/greenland-antarctica-melting-six-times-faster-than-in-the-1990s},
	abstract = {The two regions have lost 6.4 trillion tons of ice in three decades; unabated, this rate of melting could cause flooding that affects hundreds of millions of people by 2100.},
	urldate = {2022-07-27},
	journal = {Climate Change: Vital Signs of the Planet},
}

@article{briner_rate_2020,
	title = {Rate of mass loss from the {Greenland} {Ice} {Sheet} will exceed {Holocene} values this century},
	volume = {586},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-020-2742-6},
	doi = {10.1038/s41586-020-2742-6},
	abstract = {The Greenland Ice Sheet (GIS) is losing mass at a high rate1. Given the short-term nature of the observational record, it is difficult to assess the historical importance of this mass-loss trend. Unlike records of greenhouse gas concentrations and global temperature, in which observations have been merged with palaeoclimate datasets, there are no comparably long records for rates of GIS mass change. Here we reveal unprecedented mass loss from the GIS this century, by placing contemporary and future rates of GIS mass loss within the context of the natural variability over the past 12,000 years. We force a high-resolution ice-sheet model with an ensemble of climate histories constrained by ice-core data2. Our simulation domain covers southwestern Greenland, the mass change of which is dominated by surface mass balance. The results agree favourably with an independent chronology of the history of the GIS margin3,4. The largest pre-industrial rates of mass loss (up to 6,000 billion tonnes per century) occurred in the early Holocene, and were similar to the contemporary (ad 2000–2018) rate of around 6,100 billion tonnes per century5. Simulations of future mass loss from southwestern GIS, based on Representative Concentration Pathway (RCP) scenarios corresponding to low (RCP2.6) and high (RCP8.5) greenhouse gas concentration trajectories6, predict mass loss of between 8,800 and 35,900 billion tonnes over the twenty-first century. These rates of GIS mass loss exceed the maximum rates over the past 12,000 years. Because rates of mass loss from the southwestern GIS scale linearly5 with the GIS as a whole, our results indicate, with high confidence, that the rate of mass loss from the GIS will exceed Holocene rates this century.},
	language = {en},
	number = {7827},
	urldate = {2022-07-27},
	journal = {Nature},
	author = {Briner, Jason P. and Cuzzone, Joshua K. and Badgeley, Jessica A. and Young, Nicolás E. and Steig, Eric J. and Morlighem, Mathieu and Schlegel, Nicole-Jeanne and Hakim, Gregory J. and Schaefer, Joerg M. and Johnson, Jesse V. and Lesnek, Alia J. and Thomas, Elizabeth K. and Allan, Estelle and Bennike, Ole and Cluett, Allison A. and Csatho, Beata and de Vernal, Anne and Downs, Jacob and Larour, Eric and Nowicki, Sophie},
	month = oct,
	year = {2020},
	note = {Number: 7827
Publisher: Nature Publishing Group},
	keywords = {Cryospheric science, Palaeoclimate, Projection and prediction},
	pages = {70--74},
}

@misc{noauthor_our_nodate,
	title = {Our world is losing ice at record rate},
	url = {https://www.esa.int/Applications/Observing_the_Earth/FutureEO/CryoSat/Our_world_is_losing_ice_at_record_rate},
	abstract = {A research team – the first to carry out a survey of global ice loss using satellite data – has discovered that the rate at which ice is disappearing across the planet is speeding up. The findings also reveal that 28 trillion tonnes of ice was lost between 1994 and 2017 – equivalent to a sheet of ice 100 metres thick covering the whole of the UK.},
	language = {en},
	urldate = {2022-07-27},
}

@article{varon_quantifying_2018,
	title = {Quantifying methane point sources from fine-scale satellite observations of atmospheric methane plumes},
	volume = {11},
	issn = {1867-8548},
	url = {https://amt.copernicus.org/articles/11/5673/2018/},
	doi = {10.5194/amt-11-5673-2018},
	abstract = {Abstract. Anthropogenic methane emissions originate from a large
number of relatively small point sources. The planned GHGSat satellite fleet
aims to quantify emissions from individual point sources by measuring methane
column plumes over selected ∼10×10 km2 domains with
≤50×50 m2 pixel resolution and 1 \%–5 \%
measurement precision. Here we develop algorithms for retrieving point source
rates from such measurements. We simulate a large ensemble of instantaneous
methane column plumes at 50×50 m2 pixel resolution for a range
of atmospheric conditions using the Weather Research and Forecasting model
(WRF) in large eddy simulation (LES) mode and adding instrument noise. We
show that standard methods to infer source rates by Gaussian plume inversion
or source pixel mass balance are prone to large errors because the turbulence
cannot be properly parameterized on the small scale of instantaneous methane
plumes. The integrated mass enhancement (IME) method, which relates total
plume mass to source rate, and the cross-sectional flux method, which infers
source rate from fluxes across plume transects, are better adapted to the
problem. We show that the IME method with local measurements of
the 10 m wind speed can infer source rates with an error of
0.07–0.17 t h-1+5 \%–12 \% depending on instrument precision
(1 \%–5 \%). The cross-sectional flux method has slightly larger
errors (0.07–0.26 t h-1+8 \%–12 \%) but a simpler physical
basis. For comparison, point sources larger than 0.3 t h−1 contribute
more than 75 \% of methane emissions reported to the US Greenhouse Gas
Reporting Program. Additional error applies if local wind speed measurements
are not available and may dominate the overall error at low wind speeds. Low
winds are beneficial for source detection but detrimental for source
quantification.},
	language = {en},
	number = {10},
	urldate = {2022-04-01},
	journal = {Atmospheric Measurement Techniques},
	author = {Varon, Daniel J. and Jacob, Daniel J. and McKeever, Jason and Jervis, Dylan and Durak, Berke O. A. and Xia, Yan and Huang, Yi},
	month = oct,
	year = {2018},
	pages = {5673--5686},
}

@misc{noauthor_sentinel-2_nodate,
	title = {Sentinel-2: {ESA}'s {Optical} {High}-{Resolution} {Mission} for {GMES} {Operational} {Services} {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Sentinel-2},
	url = {https://reader.elsevier.com/reader/sd/pii/S0034425712000636?token=9EA2CA05F3E37FF3DBB991BED43ABBA6BFE32FE54419F63A16363625AEC1957DBEDDDB758EB7AD46B45D6893DF2D9F51&originRegion=us-east-1&originCreation=20220202041703},
	language = {en},
	urldate = {2022-02-02},
	doi = {10.1016/j.rse.2011.11.026},
}

@misc{noauthor_sentinel-2_nodate-1,
	title = {Sentinel-2: {ESA}'s {Optical} {High}-{Resolution} {Mission} for {GMES} {Operational} {Services} - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S0034425712000636},
	urldate = {2022-02-02},
}

@article{delwart_esa_nodate,
	title = {{ESA} {Standard} {Document}},
	language = {en},
	number = {1},
	author = {Delwart, Steven},
	pages = {64},
}

@misc{noauthor_sentinel-2_nodate-2,
	title = {Sentinel-2 - {Missions} - {Sentinel} {Online} - {Sentinel} {Online}},
	url = {https://sentinel.esa.int/web/sentinel/missions/sentinel-2},
	urldate = {2022-02-02},
}

@misc{noauthor_sentinel-2_nodate-3,
	title = {Sentinel-2},
	url = {https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2},
	language = {en},
	urldate = {2022-02-02},
}

@article{ruder_overview_2017,
	title = {An overview of gradient descent optimization algorithms},
	url = {http://arxiv.org/abs/1609.04747},
	abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
	urldate = {2022-02-02},
	journal = {arXiv:1609.04747 [cs]},
	author = {Ruder, Sebastian},
	month = jun,
	year = {2017},
	note = {arXiv: 1609.04747},
	keywords = {Computer Science - Machine Learning},
}

@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2022-02-02},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
}

@article{simonyan_very_2015-2,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2022-02-02},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv: 1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{szegedy_rethinking_2016,
	address = {Las Vegas, NV, USA},
	title = {Rethinking the {Inception} {Architecture} for {Computer} {Vision}},
	isbn = {978-1-4673-8851-1},
	url = {http://ieeexplore.ieee.org/document/7780677/},
	doi = {10.1109/CVPR.2016.308},
	abstract = {Convolutional networks are at the core of most stateof-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efﬁciency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efﬁciently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classiﬁcation challenge validation set demonstrate substantial gains over the state of the art: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5\% top-5 error and 17.3\% top-1 error.},
	language = {en},
	urldate = {2022-02-02},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	month = jun,
	year = {2016},
	pages = {2818--2826},
}

@inproceedings{he_deep_2016,
	address = {Las Vegas, NV, USA},
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	isbn = {978-1-4673-8851-1},
	url = {http://ieeexplore.ieee.org/document/7780459/},
	doi = {10.1109/CVPR.2016.90},
	abstract = {Deeper neural networks are more difﬁcult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [41] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classiﬁcation task. We also present analysis on CIFAR-10 with 100 and 1000 layers.},
	language = {en},
	urldate = {2022-02-02},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = jun,
	year = {2016},
	pages = {770--778},
}

@article{long_fully_2014,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	url = {https://arxiv.org/abs/1411.4038v2},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20\% relative improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes one third of a second for a typical image.},
	language = {en},
	urldate = {2022-02-02},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	month = nov,
	year = {2014},
}

@article{chen_rethinking_2017,
	title = {Rethinking {Atrous} {Convolution} for {Semantic} {Image} {Segmentation}},
	url = {https://arxiv.org/abs/1706.05587v3},
	abstract = {In this work, we revisit atrous convolution, a powerful tool to explicitly adjust filter's field-of-view as well as control the resolution of feature responses computed by Deep Convolutional Neural Networks, in the application of semantic image segmentation. To handle the problem of segmenting objects at multiple scales, we design modules which employ atrous convolution in cascade or in parallel to capture multi-scale context by adopting multiple atrous rates. Furthermore, we propose to augment our previously proposed Atrous Spatial Pyramid Pooling module, which probes convolutional features at multiple scales, with image-level features encoding global context and further boost performance. We also elaborate on implementation details and share our experience on training our system. The proposed `DeepLabv3' system significantly improves over our previous DeepLab versions without DenseCRF post-processing and attains comparable performance with other state-of-art models on the PASCAL VOC 2012 semantic image segmentation benchmark.},
	language = {en},
	urldate = {2022-02-02},
	author = {Chen, Liang-Chieh and Papandreou, George and Schroff, Florian and Adam, Hartwig},
	month = jun,
	year = {2017},
}

@article{mommert_power_2021,
	title = {Power {Plant} {Classification} from {Remote} {Imaging} with {Deep} {Learning}},
	url = {http://arxiv.org/abs/2107.10894},
	abstract = {Satellite remote imaging enables the detailed study of land use patterns on a global scale. We investigate the possibility to improve the information content of traditional land use classification by identifying the nature of industrial sites from medium-resolution remote sensing images. In this work, we focus on classifying different types of power plants from Sentinel-2 imaging data. Using a ResNet-50 deep learning model, we are able to achieve a mean accuracy of 90.0\% in distinguishing 10 different power plant types and a background class. Furthermore, we are able to identify the cooling mechanisms utilized in thermal power plants with a mean accuracy of 87.5\%. Our results enable us to qualitatively investigate the energy mix from Sentinel-2 imaging data, and prove the feasibility to classify industrial sites on a global scale from freely available satellite imagery.},
	urldate = {2022-02-01},
	journal = {arXiv:2107.10894 [cs, eess]},
	author = {Mommert, Michael and Scheibenreif, Linus and Hanna, Joëlle and Borth, Damian},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.10894},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@book{world_health_organization_world_2021,
	address = {Geneva},
	title = {World health statistics 2021: monitoring health for the {SDGs}, sustainable development goals},
	isbn = {978-92-4-002705-3},
	shorttitle = {World health statistics 2021},
	url = {https://apps.who.int/iris/handle/10665/342703},
	language = {en},
	urldate = {2022-02-01},
	publisher = {World Health Organization},
	author = {{World Health Organization}},
	year = {2021},
	note = {Section: x, 121 p.},
	keywords = {Global Health, Goals, Health Priorities, Health Status Indicators, Life Expectancy, Organizational Objectives, Statistics, Sustainable Development, Universal Health Insurance},
}

@article{cusworth_quantifying_2021,
	title = {Quantifying {Global} {Power} {Plant} {Carbon} {Dioxide} {Emissions} {With} {Imaging} {Spectroscopy}},
	volume = {2},
	issn = {2576-604X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2020AV000350},
	doi = {10.1029/2020AV000350},
	abstract = {Anthropogenic carbon dioxide (CO2) emissions dominate uncertainties in the global carbon budget. Global inventories, such as the National Greenhouse Gas Inventories, have latencies of 12–24 months and may not keep pace with rapidly changing infrastructure, particularly in the developing world. Our work reveals that airborne and satellite imaging spectrometers provide 3–30 m spatial resolution and accurate quantification of CO2 emissions at the facility scale. Examples from 17 coal and gas fired power plants across the United States demonstrate robust correlation and 21\% agreement on average between our remotely sensed estimates and simultaneous in situ measured emissions. We highlight four examples of coal-fired power plants in India, Poland, and South Korea, where we quantify significant carbon dioxide emissions from power plants where limited public emissions data exist. Leveraging previous work on methane (CH4) plume detection, we present a strategy to exploit joint CO2 and CH4 plume imaging to quantify carbon emissions across widely distributed industrial infrastructure, including facilities that co-emit CO2 and CH4. We show an example of a coal operation, where we attribute 25\% of greenhouse gas emissions to coal extraction (CH4) and the remaining 75\% to energy generation (CO2). Satellite spectrometers could track high emitting coal-fired power plants that collectively contribute to 60\% or more of global coal CO2 emissions. Multiple revisits and coordinated targeting of these high emitting facilities by multiple spaceborne instruments will be key to reducing uncertainties in global anthropogenic CO2 emissions and supporting emissions mitigation strategies.},
	language = {en},
	number = {2},
	urldate = {2022-02-01},
	journal = {AGU Advances},
	author = {Cusworth, Daniel H. and Duren, Riley M. and Thorpe, Andrew K. and Eastwood, Michael L. and Green, Robert O. and Dennison, Philip E. and Frankenberg, Christian and Heckler, Joseph W. and Asner, Gregory P. and Miller, Charles E.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2020AV000350},
	keywords = {Carbon dioxide, coal, imaging spectroscopy, power plant},
	pages = {e2020AV000350},
}

@article{eldering_orbiting_2017,
	title = {The {Orbiting} {Carbon} {Observatory}-2 early science investigations of regional carbon dioxide fluxes},
	volume = {358},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5668686/},
	doi = {10.1126/science.aam5745},
	abstract = {NASA’s Orbiting Carbon Observatory-2 (OCO-2) mission was motivated by the need to diagnose how the increasing concentration of atmospheric carbon dioxide (CO2) is altering the productivity of the biosphere and the uptake of CO2 by the oceans. Launched on July 2, 2014, OCO-2 provides retrievals of the total column carbon dioxide (XCO2) as well as the fluorescence from chlorophyll in terrestrial plants. The seasonal pattern of uptake by the terrestrial biosphere is recorded in fluorescence and the drawdown of XCO2 during summer. Launched just prior to one of the most intense El Niños of the past century, OCO-2 measurements of XCO2 and fluorescence record the impact of the large change in ocean temperature and rainfall on uptake and release of CO2 by the oceans and biosphere.},
	number = {6360},
	urldate = {2022-02-01},
	journal = {Science (New York, N.Y.)},
	author = {Eldering, A. and Wennberg, P.O. and Crisp, D. and Schimel, D. and Gunson, M.R. and Chatterjee, A. and Liu, J. and Schwandner, F. M. and Sun, Y. and O’Dell, C.W. and Frankenberg, C. and Taylor, T. and Fisher, B. and Osterman, G.B. and Wunch, D. and Hakkarainen, J. and Tamminen, J. and Weir, B.},
	month = oct,
	year = {2017},
	pmid = {29026012},
	pmcid = {PMC5668686},
	pages = {eaam5745},
}

@article{boesch_monitoring_2021,
	title = {Monitoring {Greenhouse} {Gases} from {Space}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/13/14/2700},
	doi = {10.3390/rs13142700},
	abstract = {The increase in atmospheric greenhouse gas concentrations of CO2 and CH4, due to human activities, is the main driver of the observed increase in surface temperature by more than 1 °C since the pre-industrial era. At the 2015 United Nations Climate Change Conference held in Paris, most nations agreed to reduce greenhouse gas emissions to limit the increase in global surface temperature to 1.5 °C. Satellite remote sensing of CO2 and CH4 is now well established thanks to missions such as NASA’s OCO-2 and the Japanese GOSAT missions, which have allowed us to build a long-term record of atmospheric GHG concentrations from space. They also give us a first glimpse into CO2 and CH4 enhancements related to anthropogenic emission, which helps to pave the way towards the future missions aimed at a Monitoring \& Verification Support (MVS) capacity for the global stock take of the Paris agreement. China plays an important role for the global carbon budget as the largest source of anthropogenic carbon emissions but also as a region of increased carbon sequestration as a result of several reforestation projects. Over the last 10 years, a series of projects on mitigation of carbon emission has been started in China, including the development of the first Chinese greenhouse gas monitoring satellite mission, TanSat, which was successfully launched on 22 December 2016. Here, we summarise the results of a collaborative project between European and Chinese teams under the framework of the Dragon-4 programme of ESA and the Ministry of Science and Technology (MOST) to characterize and evaluate the datasets from the TanSat mission by retrieval intercomparisons and ground-based validation and to apply model comparisons and surface flux inversion methods to TanSat and other CO2 missions, with a focus on China.},
	language = {en},
	number = {14},
	urldate = {2022-02-01},
	journal = {Remote Sensing},
	author = {Boesch, Hartmut and Liu, Yi and Tamminen, Johanna and Yang, Dongxu and Palmer, Paul I. and Lindqvist, Hannakaisa and Cai, Zhaonan and Che, Ke and Di Noia, Antonio and Feng, Liang and Hakkarainen, Janne and Ialongo, Iolanda and Kalaitzi, Nikoleta and Karppinen, Tomi and Kivi, Rigel and Kivimäki, Ella and Parker, Robert J. and Preval, Simon and Wang, Jing and Webb, Alex J. and Yao, Lu and Chen, Huilin},
	month = jan,
	year = {2021},
	note = {Number: 14
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {atmospheric transport modelling, greenhouse gases, satellite remote sensing, validation},
	pages = {2700},
}

@article{smol_climate_2012,
	title = {Climate {Change}: {A} planet in flux},
	volume = {483},
	copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	shorttitle = {Climate {Change}},
	url = {https://www.nature.com/articles/483S12a},
	doi = {10.1038/483S12a},
	abstract = {How is life on Earth reacting to climate change?},
	language = {en},
	number = {7387},
	urldate = {2022-01-31},
	journal = {Nature},
	author = {Smol, John P.},
	month = mar,
	year = {2012},
	note = {Number: 7387
Publisher: Nature Publishing Group},
	keywords = {Atmospheric science, Climate change},
	pages = {S12--S15},
}

@article{noauthor_countries_nodate,
	title = {Countries’ climate pledges built on flawed data, {Post} investigation finds},
	issn = {0190-8286},
	url = {https://www.washingtonpost.com/climate-environment/interactive/2021/greenhouse-gas-emissions-pledges-data/},
	abstract = {An examination of 196 country reports to the United Nations reveals a giant gap between what nations declare their emissions to be versus the greenhouse gases they are sending into the atmosphere. The gap ranges from at least 8.5 billion to as high as 13.3 billion tons a year -- surpassing the annual emissions of China.},
	language = {en-US},
	urldate = {2022-01-31},
	journal = {Washington Post},
}

@misc{noauthor_climate_nodate,
	title = {Climate pledges built on flawed emissions data, {Post} investigation finds - {Washington} {Post}},
	url = {https://www.washingtonpost.com/climate-environment/interactive/2021/greenhouse-gas-emissions-pledges-data/},
	urldate = {2022-01-31},
}

@article{noauthor_climate_nodate-1,
	title = {Climate {Change}: {Evidence} \& {Causes} 2020},
	language = {en},
	pages = {36},
}

@misc{us_epa_emc_2016,
	type = {Other {Policies} and {Guidance}},
	title = {{EMC}: {Continuous} {Emission} {Monitoring} {Systems}},
	shorttitle = {{EMC}},
	url = {https://www.epa.gov/emc/emc-continuous-emission-monitoring-systems},
	abstract = {CEMS are required under some EPA regulations for either continual compliance determinations or determination of exceedances of the standards.},
	language = {en},
	urldate = {2022-01-31},
	author = {US EPA, OAR},
	month = jul,
	year = {2016},
}

@misc{brownlee_regression_2021,
	title = {Regression {Metrics} for {Machine} {Learning}},
	url = {https://machinelearningmastery.com/regression-metrics-for-machine-learning/},
	abstract = {Regression refers to predictive modeling problems that involve predicting a numeric value. It is different from classification that involves predicting […]},
	language = {en-US},
	urldate = {2022-01-31},
	journal = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	month = jan,
	year = {2021},
}

@article{grant_reducing_2021,
	title = {Reducing {CO2} emissions by targeting the world's hyper-polluting power plants {\textbackslash}ast},
	volume = {16},
	issn = {1748-9326},
	url = {https://doi.org/10.1088/1748-9326/ac13f1},
	doi = {10.1088/1748-9326/ac13f1},
	abstract = {Combusting fossil fuels to produce electricity is the single largest contributor to sector-level, anthropogenic carbon pollution. Because sector-wide policies are often too unwieldy to implement, however, some researchers have recommended reducing electricity-based CO2 emissions by targeting the most extreme emitters of each nation’s electricity industry. Here, we use a unique international data source to measure national disproportionalities in power plant CO2 emissions and estimate the fraction of each country’s electricity-based CO2 emissions that would be reduced if its most profligate polluters lowered their emission intensities, switched to gas fuels, and incorporated carbon capture and storage systems. We find that countries’ disproportionalities vary greatly and have mostly grown over time. We also find that 17\%–49\% of the world’s CO2 emissions from electricity generation could be eliminated depending on the intensity standards, fuels, or carbon capture technologies adopted by hyper-emitting plants. This suggests that policies aimed at improving the environmental performance of ‘super polluters’ are effective strategies for transitioning to decarbonized energy systems.},
	language = {en},
	number = {9},
	urldate = {2022-01-31},
	journal = {Environmental Research Letters},
	author = {Grant, Don and Zelinka, David and Mitova, Stefania},
	month = aug,
	year = {2021},
	note = {Publisher: IOP Publishing},
	pages = {094022},
}

@article{akiba_optuna_2019,
	title = {Optuna: {A} {Next}-generation {Hyperparameter} {Optimization} {Framework}},
	shorttitle = {Optuna},
	url = {http://arxiv.org/abs/1907.10902},
	abstract = {The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).},
	urldate = {2022-01-31},
	journal = {arXiv:1907.10902 [cs, stat]},
	author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.10902},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{jadon_survey_2020,
	title = {A survey of loss functions for semantic segmentation},
	url = {http://arxiv.org/abs/2006.14822},
	doi = {10.1109/CIBCB48159.2020.9277638},
	abstract = {Image Segmentation has been an active field of research as it has a wide range of applications, ranging from automated disease detection to self-driving cars. In the past five years, various papers came up with different objective loss functions used in different cases such as biased data, sparse segmentation, etc. In this paper, we have summarized some of the well-known loss functions widely used for Image Segmentation and listed out the cases where their usage can help in fast and better convergence of a model. Furthermore, we have also introduced a new log-cosh dice loss function and compared its performance on the NBFS skull-segmentation open-source data-set with widely used loss functions. We also showcased that certain loss functions perform well across all data-sets and can be taken as a good baseline choice in unknown data distribution scenarios. Our code is available at Github: https://github.com/shruti-jadon/Semantic-Segmentation-Loss-Functions.},
	urldate = {2022-01-31},
	journal = {2020 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)},
	author = {Jadon, Shruti},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.14822},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	pages = {1--7},
}

@article{ronneberger_u-net_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	urldate = {2022-01-31},
	journal = {arXiv:1505.04597 [cs]},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv: 1505.04597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{hersbach_era5_2020,
	title = {The {ERA5} global reanalysis},
	volume = {146},
	issn = {1477-870X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qj.3803},
	doi = {10.1002/qj.3803},
	abstract = {Within the Copernicus Climate Change Service (C3S), ECMWF is producing the ERA5 reanalysis which, once completed, will embody a detailed record of the global atmosphere, land surface and ocean waves from 1950 onwards. This new reanalysis replaces the ERA-Interim reanalysis (spanning 1979 onwards) which was started in 2006. ERA5 is based on the Integrated Forecasting System (IFS) Cy41r2 which was operational in 2016. ERA5 thus benefits from a decade of developments in model physics, core dynamics and data assimilation. In addition to a significantly enhanced horizontal resolution of 31 km, compared to 80 km for ERA-Interim, ERA5 has hourly output throughout, and an uncertainty estimate from an ensemble (3-hourly at half the horizontal resolution). This paper describes the general set-up of ERA5, as well as a basic evaluation of characteristics and performance, with a focus on the dataset from 1979 onwards which is currently publicly available. Re-forecasts from ERA5 analyses show a gain of up to one day in skill with respect to ERA-Interim. Comparison with radiosonde and PILOT data prior to assimilation shows an improved fit for temperature, wind and humidity in the troposphere, but not the stratosphere. A comparison with independent buoy data shows a much improved fit for ocean wave height. The uncertainty estimate reflects the evolution of the observing systems used in ERA5. The enhanced temporal and spatial resolution allows for a detailed evolution of weather systems. For precipitation, global-mean correlation with monthly-mean GPCP data is increased from 67\% to 77\%. In general, low-frequency variability is found to be well represented and from 10 hPa downwards general patterns of anomalies in temperature match those from the ERA-Interim, MERRA-2 and JRA-55 reanalyses.},
	language = {en},
	number = {730},
	urldate = {2022-01-31},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Hersbach, Hans and Bell, Bill and Berrisford, Paul and Hirahara, Shoji and Horányi, András and Muñoz-Sabater, Joaquín and Nicolas, Julien and Peubey, Carole and Radu, Raluca and Schepers, Dinand and Simmons, Adrian and Soci, Cornel and Abdalla, Saleh and Abellan, Xavier and Balsamo, Gianpaolo and Bechtold, Peter and Biavati, Gionata and Bidlot, Jean and Bonavita, Massimo and De Chiara, Giovanna and Dahlgren, Per and Dee, Dick and Diamantakis, Michail and Dragani, Rossana and Flemming, Johannes and Forbes, Richard and Fuentes, Manuel and Geer, Alan and Haimberger, Leo and Healy, Sean and Hogan, Robin J. and Hólm, Elías and Janisková, Marta and Keeley, Sarah and Laloyaux, Patrick and Lopez, Philippe and Lupu, Cristina and Radnoti, Gabor and de Rosnay, Patricia and Rozum, Iryna and Vamborg, Freja and Villaume, Sebastien and Thépaut, Jean-Noël},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/qj.3803},
	keywords = {Copernicus Climate Change Service, ERA5, climate reanalysis, data assimilation, historical observations},
	pages = {1999--2049},
}

@article{hanna_multitask_nodate,
	title = {Multitask {Learning} for {Estimating} {Power} {Plant} {Greenhouse} {Gas} {Emissions} from {Satellite} {Imagery}},
	abstract = {The burning of fossil fuels produces large amounts of carbon dioxide (CO2), a major Greenhouse Gas (GHG) and a main driver of Climate Change. Quantifying GHG emissions is crucial for accurate predictions of climate effects and to enforce emission trading schemes. The reporting of such emissions is only required in some countries, resulting in insufﬁcient global coverage. In this work, we propose an end-to-end method to predict power generation rates for fossil fuel power plants from satellite images based on which we estimate GHG emission rates. We present a multitask deep learning approach able to simultaneously predict: (i) the pixel-area covered by plumes from a single satellite image of a power plant, (ii) the type of ﬁred fuel, and (iii) the power generation rate. We then convert the predicted power generation rate into estimates for the rate at which CO2 is being emitted. Experimental results show that our model approach allows us to estimate the power generation rate of a power plant to within 139 MW (MAE, for a mean sample power plant capacity of 1177 MW) from a single satellite image and CO2 emission rates to within 311 t/h. This multitask learning approach improves the power generation estimation MAE by 39\% compared to a baseline single-task network trained on the same dataset.},
	language = {en},
	author = {Hanna, Joëlle and Scheibenreif, Linus and Mommert, Michael and Borth, Damian},
	pages = {6},
}

@article{sheng_ognet_nodate,
	title = {{OGNet}: {Towards} a {Global} {Oil} and {Gas} {Infrastructure} {Database} using {Deep} {Learning} on {Remotely} {Sensed} {Imagery}},
	abstract = {At least a quarter of the warming that the Earth is experiencing today is due to anthropogenic methane emissions. There are multiple satellites in orbit and planned for launch in the next few years which can detect and quantify these emissions; however, to attribute methane emissions to their sources on the ground, a comprehensive database of the locations and characteristics of emission sources worldwide is essential. In this work, we develop deep learning algorithms that leverage freely available high-resolution aerial imagery to automatically detect oil and gas infrastructure, one of the largest contributors to global methane emissions. We use the best algorithm, which we call OGNet, together with expert review to identify the locations of oil reﬁneries and petroleum terminals in the U.S. We show that OGNet detects many facilities which are not present in four standard public datasets of oil and gas infrastructure. All detected facilities are associated with characteristics known to contribute to methane emissions, including the infrastructure type and the number of storage tanks. The data curated and produced in this study is freely available at http://stanfordmlgroup.github.io/projects/ognet.},
	language = {en},
	author = {Sheng, Hao and Irvin, Jeremy and Munukutla, Sasankh and Zhang, Shawn and Cross, Christopher and Story, Kyle and Rustowicz, Rose and Elsworth, Cooper and Yang, Zutao and Omara, Mark and Gautam, Ritesh and Jackson, Robert B and Ng, Andrew Y},
	pages = {8},
}

@article{couture_towards_nodate,
	title = {Towards {Tracking} the {Emissions} of {Every} {Power} {Plant} on the {Planet}},
	abstract = {Greenhouse gases emitted from fossil-fuel-burning power plants are a major contributor to climate change. Current methods to track emissions from individual sources are expensive and only used in a few countries. While carbon dioxide concentrations can be measured globally using remote sensing, background ﬂuctuations and low spatial resolution make it difﬁcult to attribute emissions to individual sources. We use machine learning to infer power generation and emissions from visible and thermal power plant signatures in satellite images. By training on a data set of power plants for which we know the generation or emissions, we are able to apply our models globally. This paper demonstrates initial progress on this project by predicting whether a power plant is on or off from a single satellite image.},
	language = {en},
	author = {Couture, Heather D and O’Connor, Joseph and Mitchell, Grace and Söldner-Rembold, Isabella and D’souza, Durand and Karra, Krishna and Zhang, Keto D and Kargar, Ali Rouzbeh and Kassel, Thomas and Goldman, Brian W and Tyrrell, Daniel and Czerwinski, Wanda and Talekar, Alok and McCormick, Colin},
	pages = {9},
}

@article{apte_high-resolution_2017,
	title = {High-{Resolution} {Air} {Pollution} {Mapping} with {Google} {Street} {View} {Cars}: {Exploiting} {Big} {Data}},
	volume = {51},
	issn = {0013-936X},
	shorttitle = {High-{Resolution} {Air} {Pollution} {Mapping} with {Google} {Street} {View} {Cars}},
	url = {https://doi.org/10.1021/acs.est.7b00891},
	doi = {10.1021/acs.est.7b00891},
	abstract = {Air pollution affects billions of people worldwide, yet ambient pollution measurements are limited for much of the world. Urban air pollution concentrations vary sharply over short distances (≪1 km) owing to unevenly distributed emission sources, dilution, and physicochemical transformations. Accordingly, even where present, conventional fixed-site pollution monitoring methods lack the spatial resolution needed to characterize heterogeneous human exposures and localized pollution hotspots. Here, we demonstrate a measurement approach to reveal urban air pollution patterns at 4–5 orders of magnitude greater spatial precision than possible with current central-site ambient monitoring. We equipped Google Street View vehicles with a fast-response pollution measurement platform and repeatedly sampled every street in a 30-km2 area of Oakland, CA, developing the largest urban air quality data set of its type. Resulting maps of annual daytime NO, NO2, and black carbon at 30 m-scale reveal stable, persistent pollution patterns with surprisingly sharp small-scale variability attributable to local sources, up to 5–8× within individual city blocks. Since local variation in air quality profoundly impacts public health and environmental equity, our results have important implications for how air pollution is measured and managed. If validated elsewhere, this readily scalable measurement approach could address major air quality data gaps worldwide.},
	number = {12},
	urldate = {2022-01-31},
	journal = {Environmental Science \& Technology},
	author = {Apte, Joshua S. and Messier, Kyle P. and Gani, Shahzad and Brauer, Michael and Kirchstetter, Thomas W. and Lunden, Melissa M. and Marshall, Julian D. and Portier, Christopher J. and Vermeulen, Roel C.H. and Hamburg, Steven P.},
	month = jun,
	year = {2017},
	note = {Publisher: American Chemical Society},
	pages = {6999--7008},
}

@misc{monroe_keeling_nodate,
	title = {The {Keeling} {Curve}},
	url = {https://keelingcurve.ucsd.edu},
	abstract = {The Keeling Curve is a daily record of global atmospheric carbon dioxide concentration maintained by Scripps Institution of Oceanography at UC San Diego.},
	language = {en-US},
	urldate = {2022-01-31},
	journal = {The Keeling Curve},
	author = {Monroe, Rob},
}

@misc{sridhar_filling_2021,
	title = {Filling the {Post}-{Paris} {Gap}},
	url = {https://medium.com/climate-trace-the-source/filling-the-post-paris-gap-8cd9a1ee3eeb},
	abstract = {Bringing up-to-date emissions data to the world’s countries},
	language = {en},
	urldate = {2022-01-30},
	journal = {Climate TRACE: The Source},
	author = {Sridhar, Lekha},
	month = oct,
	year = {2021},
}

@misc{noauthor_sixth_nodate,
	title = {Sixth {Assessment} {Report} — {IPCC}},
	url = {https://www.ipcc.ch/assessment-report/ar6/},
	urldate = {2022-01-30},
}

@misc{noauthor_what_nodate,
	title = {What is transparency and reporting? {\textbar} {UNFCCC}},
	url = {https://unfccc.int/process-and-meetings/transparency-and-reporting/the-big-picture/what-is-transparency-and-reporting},
	urldate = {2022-01-30},
}

@misc{noauthor_air_nodate,
	title = {Air pollution},
	url = {https://www.who.int/health-topics/air-pollution#tab=tab_1},
	urldate = {2022-01-30},
}

@misc{noauthor_where_nodate,
	title = {Where greenhouse gases come from - {U}.{S}. {Energy} {Information} {Administration} ({EIA})},
	url = {https://www.eia.gov/energyexplained/energy-and-the-environment/where-greenhouse-gases-come-from.php},
	urldate = {2022-01-30},
}

@misc{noauthor_frequently_nodate,
	title = {Frequently {Asked} {Questions} ({FAQs}) - {U}.{S}. {Energy} {Information} {Administration} ({EIA})},
	url = {https://www.eia.gov/tools/faqs/faq.php},
	abstract = {Energy Information Administration - EIA - Official Energy Statistics from the U.S. Government},
	urldate = {2022-01-30},
}

@misc{noauthor_surveillance_nodate,
	title = {Surveillance {Under} the {USA}/{PATRIOT} {Act} {\textbar} {American} {Civil} {Liberties} {Union}},
	url = {https://www.aclu.org/other/surveillance-under-usapatriot-act},
	urldate = {2022-01-30},
}

@misc{noauthor_is_2017,
	title = {Is the {iPhone} {X}'s facial recognition racist?},
	url = {https://www.newsweek.com/iphone-x-racist-apple-refunds-device-cant-tell-chinese-people-apart-woman-751263},
	abstract = {Apple has refunded a Chinese woman after the device failed to distinguish her from her colleague, who is also Chinese.},
	language = {en},
	urldate = {2022-01-30},
	journal = {Newsweek},
	month = dec,
	year = {2017},
	note = {Section: World},
}

@misc{noauthor_demographics_nodate,
	title = {Demographics of {Internet} and {Home} {Broadband} {Usage} in the {United} {States} {\textbar} {Pew} {Research} {Center}},
	url = {https://www.pewresearch.org/internet/fact-sheet/internet-broadband/},
	urldate = {2022-01-30},
}

@misc{mooney_countries_nodate,
	title = {Countries’ climate pledges built on flawed data, {Post} investigation finds},
	url = {https://www.washingtonpost.com/climate-environment/interactive/2021/greenhouse-gas-emissions-pledges-data/},
	abstract = {An examination of 196 country reports to the United Nations reveals a giant gap between what nations declare their emissions to be versus the greenhouse gases they are sending into the atmosphere. The gap ranges from at least 8.5 billion to as high as 13.3 billion tons a year -- surpassing the annual emissions of China.},
	language = {en},
	urldate = {2022-01-30},
	journal = {Washington Post},
	author = {Mooney, Chris and Eilperin, Juliet and Butler, Desmond and Muyskens, John and Narayanswamy, Anu and Ahmed, Naema},
}

@article{drusch_sentinel-2_2012-1,
	series = {The {Sentinel} {Missions} - {New} {Opportunities} for {Science}},
	title = {Sentinel-2: {ESA}'s {Optical} {High}-{Resolution} {Mission} for {GMES} {Operational} {Services}},
	volume = {120},
	issn = {0034-4257},
	shorttitle = {Sentinel-2},
	url = {https://www.sciencedirect.com/science/article/pii/S0034425712000636},
	doi = {10.1016/j.rse.2011.11.026},
	abstract = {Global Monitoring for Environment and Security (GMES) is a joint initiative of the European Commission (EC) and the European Space Agency (ESA), designed to establish a European capacity for the provision and use of operational monitoring information for environment and security applications. ESA's role in GMES is to provide the definition and the development of the space- and ground-related system elements. GMES Sentinel-2 mission provides continuity to services relying on multi-spectral high-resolution optical observations over global terrestrial surfaces. The key mission objectives for Sentinel-2 are: (1) To provide systematic global acquisitions of high-resolution multi-spectral imagery with a high revisit frequency, (2) to provide enhanced continuity of multi-spectral imagery provided by the SPOT (Satellite Pour l'Observation de la Terre) series of satellites, and (3) to provide observations for the next generation of operational products such as land-cover maps, land change detection maps, and geophysical variables. Consequently, Sentinel-2 will directly contribute to the Land Monitoring, Emergency Response, and Security services. The corresponding user requirements have driven the design toward a dependable multi-spectral Earth-observation system featuring the Multi Spectral Instrument (MSI) with 13 spectral bands spanning from the visible and the near infrared to the short wave infrared. The spatial resolution varies from 10m to 60m depending on the spectral band with a 290km field of view. This unique combination of high spatial resolution, wide field of view and spectral coverage will represent a major step forward compared to current multi-spectral missions. The mission foresees a series of satellites, each having a 7.25-year lifetime over a 15-year period starting with the launch of Sentinel-2A foreseen in 2013. During full operations two identical satellites will be maintained in the same orbit with a phase delay of 180° providing a revisit time of five days at the equator. This paper provides an overview of the GMES Sentinel-2 mission including a technical system concept overview, image quality, Level 1 data processing and operational applications.},
	language = {en},
	urldate = {2021-09-19},
	journal = {Remote Sensing of Environment},
	author = {Drusch, M. and Del Bello, U. and Carlier, S. and Colin, O. and Fernandez, V. and Gascon, F. and Hoersch, B. and Isola, C. and Laberinti, P. and Martimort, P. and Meygret, A. and Spoto, F. and Sy, O. and Marchese, F. and Bargellini, P.},
	month = may,
	year = {2012},
	keywords = {GMES, Land cover classification, Optical multi-spectral instrument, Remote sensing, Sentinel-2},
	pages = {25--36},
}

@article{couture_towards_nodate-1,
	title = {Towards {Tracking} the {Emissions} of {Every} {Power} {Plant} on the {Planet}},
	abstract = {Greenhouse gases emitted from fossil-fuel-burning power plants are a major contributor to climate change. Current methods to track emissions from individual sources are expensive and only used in a few countries. While carbon dioxide concentrations can be measured globally using remote sensing, background ﬂuctuations and low spatial resolution make it difﬁcult to attribute emissions to individual sources. We use machine learning to infer power generation and emissions from visible and thermal power plant signatures in satellite images. By training on a data set of power plants for which we know the generation or emissions, we are able to apply our models globally. This paper demonstrates initial progress on this project by predicting whether a power plant is on or off from a single satellite image.},
	language = {en},
	author = {Couture, Heather D and O’Connor, Joseph and Mitchell, Grace and Söldner-Rembold, Isabella and D’souza, Durand and Karra, Krishna and Zhang, Keto D and Kargar, Ali Rouzbeh and Kassel, Thomas and Goldman, Brian W and Tyrrell, Daniel and Czerwinski, Wanda and Talekar, Alok and McCormick, Colin},
	pages = {9},
}

@incollection{ravi_krishna_air_2021,
	address = {Singapore},
	series = {Springer {Transactions} in {Civil} and {Environmental} {Engineering}},
	title = {Air {Quality} {Monitoring} and {Techniques}},
	isbn = {9789811555114},
	url = {https://doi.org/10.1007/978-981-15-5511-4_2},
	abstract = {The important sources of air pollution can be identified with the installation of ambient air quality monitoring station. The sampling with monitoring station can provide current status of air quality of that particular area. This chapter describes the different measuring and analytical technique for monitoring of air quality. The different method for the collection of pollutant is also explained. The types of the gaseous monitoring techniques were described in Sects. 2.3 and its subsections. The different measurement techniques of particulate pollutants were explained in Sects. 2.4. The Section 2.5 explained some of the important concepts of data quality assurance and quality control (QA/QC) with reference to the analysis of vapour-phase chemical composition in air.},
	language = {en},
	urldate = {2021-09-19},
	booktitle = {Urban {Air} {Quality} {Monitoring}, {Modelling} and {Human} {Exposure} {Assessment}},
	publisher = {Springer},
	author = {Ravi Krishna, R. and Shiva Nagendra, S. M. and {Saraswati} and Diya, M.},
	editor = {Shiva Nagendra, S. M. and Schlink, Uwe and Müller, Andrea and Khare, Mukesh},
	year = {2021},
	doi = {10.1007/978-981-15-5511-4_2},
	pages = {13--34},
}

@article{scheibenreif_estimation_2021,
	title = {Estimation of {Air} {Pollution} with {Remote} {Sensing} {Data}: {Revealing} {Greenhouse} {Gas} {Emissions} from {Space}},
	shorttitle = {Estimation of {Air} {Pollution} with {Remote} {Sensing} {Data}},
	url = {http://arxiv.org/abs/2108.13902},
	abstract = {Air pollution is a major driver of climate change. Anthropogenic emissions from the burning of fossil fuels for transportation and power generation emit large amounts of problematic air pollutants, including Greenhouse Gases (GHGs). Despite the importance of limiting GHG emissions to mitigate climate change, detailed information about the spatial and temporal distribution of GHG and other air pollutants is difficult to obtain. Existing models for surface-level air pollution rely on extensive land-use datasets which are often locally restricted and temporally static. This work proposes a deep learning approach for the prediction of ambient air pollution that only relies on remote sensing data that is globally available and frequently updated. Combining optical satellite imagery with satellite-based atmospheric column density air pollution measurements enables the scaling of air pollution estimates (in this case NO\$\_2\$) to high spatial resolution (up to \${\textbackslash}sim\$10m) at arbitrary locations and adds a temporal component to these estimates. The proposed model performs with high accuracy when evaluated against air quality measurements from ground stations (mean absolute error \${\textless}\$6\${\textasciitilde}{\textbackslash}mu g/m{\textasciicircum}3\$). Our results enable the identification and temporal monitoring of major sources of air pollution and GHGs.},
	urldate = {2021-09-19},
	journal = {arXiv:2108.13902 [cs]},
	author = {Scheibenreif, Linus and Mommert, Michael and Borth, Damian},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.13902},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, I.4},
}

@misc{noauthor_air_nodate-1,
	title = {Air quality status and trends in {Europe} {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S1352231014007109?token=39BBE8D829B8169B4193D47B8683394790FCCDA1FA229728747A97F42CACCB6B0B7A859FB81C6622658D3197720A54AD&originRegion=us-east-1&originCreation=20210919095602},
	language = {en},
	urldate = {2021-09-19},
	doi = {10.1016/j.atmosenv.2014.09.017},
}

@misc{noauthor_air_nodate-2,
	title = {Air quality status and trends in {Europe} - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S1352231014007109},
	urldate = {2021-09-19},
}

@article{whitehill_uncertainty_2020,
	title = {Uncertainty in collocated mobile measurements of air quality},
	volume = {7},
	issn = {2590-1621},
	doi = {10.1016/j.aeaoa.2020.100080},
	abstract = {Mobile mapping of air pollution has the potential to provide pollutant concentration data at unprecedented spatial scales. Characterizing instrument performance in the mobile context is challenging, but necessary to analyze and interpret the resulting data. We used robust statistical methods to assess mobile platform performance using data collected with the Aclima Inc. mobile air pollution measurement and data acquisition platform installed on three Google Street View cars. They were driven throughout the greater Denver metropolitan area between July 25, 2014 and August 14, 2014, measuring ozone (O3), nitrogen dioxide (NO2), nitric oxide (NO), black carbon (BC), and size-resolve particle number counts (PN) between 0.3 μm and 5.0 μm diameter. August 6, 2014 was dedicated to parked and moving collocations among the three cars, allowing an assessment of measurement precision and bias. We used the median absolute deviation (MAD) to estimate instrument precision from outdoor, parked collocations. Bias was assessed by measurements obtained from parked cars using the standard deviation of median values over a collocated measurement period, as well as by Passing-Bablok regression statistics while the cars were moving and collocated. For the moving collocation periods, we compared the distribution of 1-σ standard deviations among the 3 cars to the estimated distribution assuming only measurement uncertainty (precision and bias). The distribution of mobile measurements agreed well with the theoretical uncertainty distribution at the lower end of the distribution for O3, NO2, and PN. We assert that the difference between the actual and theoretical distributions is due to real spatial variability between pollutants. The agreement between the parked car estimates of uncertainty and that measured during the mobile collocations (at the lower quantiles) provides evidence that on-road collocation while parked could be sufficient for estimating measurement uncertainties of a mobile platform, even when extended to the moving environment.},
	language = {eng},
	journal = {Atmospheric Environment: X},
	author = {Whitehill, Andrew R. and Lunden, Melissa and Kaushik, Surender and Solomon, Paul},
	month = oct,
	year = {2020},
	pmid = {33748742},
	pmcid = {PMC7970519},
	keywords = {Black carbon Ozone, Coefficient of variation, Median absolute deviation, Mobile monitoring, Nitric oxide, Nitrogen dioxide, Particulate matter},
}

@incollection{mosley_environmental_2014,
	address = {Cham},
	series = {Environmental {History}},
	title = {Environmental {History} of {Air} {Pollution} and {Protection}},
	isbn = {978-3-319-09180-8},
	url = {https://doi.org/10.1007/978-3-319-09180-8_5},
	abstract = {Concerns about air pollution have a long and complex history. Complaints about its effects on human health and the urban environment were first voiced by the inhabitants of ancient Athens and Rome. But urban air quality worsened considerably during the Industrial Revolution, as the widespread use of coal in factories in Britain, Germany, the United States and other nations ushered in an ‘age of smoke’. Despite the tangible nature of this form of air pollution, early laws to control it were generally weak and ineffective—regardless of its high socio-environmental costs—reflecting the importance of coal-fuelled steam power to economic growth. Not until the mid-twentieth century, after major air pollution episodes such as London’s ‘Great Smog’ had demonstrated beyond doubt that polluted air was as harmful to the public’s health as polluted water supplies, were stringent national laws to abate smoke finally introduced to clear the skies over the cities of the first industrial nations. However, while the citizens of the developed world now breathe cleaner air, smoke pollution is still a significant environmental problem in many industrial cities of developing countries today. In terms of their scale, the effects of coal smoke in the nineteenth and early twentieth centuries were largely local and regional. But after the Second World War a number of invisible threats began to emerge—acid rain, photochemical smog, ozone depletion and climate change—that were transnational and global in character. It often required the cooperation of scientific experts across academic and political borders, as well as new techniques such as computer modelling, to make these new threats ‘visible’ to the public. Global environmental problems also required collective political and legislative action on the part of nations if solutions were to be found. The success of the Montreal Protocol in phasing out the use of ozone-depleting CFCs stands as a successful example of international environmental governance. However, it will need a strong commitment to international cooperation if an effective agreement to reduce greenhouse gas emissions is to be reached, particularly as global warming is a concept that the public (and many politicians) still find difficult to grasp.},
	language = {en},
	urldate = {2021-09-19},
	booktitle = {The {Basic} {Environmental} {History}},
	publisher = {Springer International Publishing},
	author = {Mosley, Stephen},
	editor = {Agnoletti, Mauro and Neri Serneri, Simone},
	year = {2014},
	doi = {10.1007/978-3-319-09180-8_5},
	keywords = {Abatement Technology, Acid Rain, Photochemical Smog, Smoke Emission, Sulphur Dioxide Emission},
	pages = {143--169},
}

@article{gupta_satellite_2006,
	title = {Satellite remote sensing of particulate matter and air quality assessment over global cities},
	volume = {40},
	issn = {1352-2310},
	url = {http://www.scopus.com/inward/record.url?scp=33748305652&partnerID=8YFLogxK},
	doi = {10.1016/j.atmosenv.2006.03.016},
	abstract = {Using 1 year of aerosol optical thickness (AOT) retrievals from the MODerate resolution Imaging Spectro-radiometer (MODIS) on board NASA's Terra and Aqua satellite along with ground measurements of PM2.5 mass concentration, we assess particulate matter air quality over different locations across the global urban areas spread over 26 locations in Sydney, Delhi, Hong Kong, New York City and Switzerland. An empirical relationship between AOT and PM2.5 mass is obtained and results show that there is an excellent correlation between the bin-averaged daily mean satellite and ground-based values with a linear correlation coefficient of 0.96. Using meteorological and other ancillary datasets, we assess the effects of wind speed, cloud cover, and mixing height (MH) on particulate matter (PM) air quality and conclude that these data are necessary to further apply satellite data for air quality research. Our study clearly demonstrates that satellite-derived AOT is a good surrogate for monitoring PM air quality over the earth. However, our analysis shows that the PM2.5-AOT relationship strongly depends on aerosol concentrations, ambient relative humidity (RH), fractional cloud cover and height of the mixing layer. Highest correlation between MODIS AOT and PM2.5 mass is found under clear sky conditions with less than 40-50\% RH and when atmospheric MH ranges from 100 to 200 m. Future remote sensing sensors such as Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observations (CALIPSO) that have the capability to provide vertical distribution of aerosols will further enhance our ability to monitor and forecast air pollution. This study is among the first to examine the relationship between satellite and ground measurements over several global locations.},
	number = {30},
	urldate = {2021-09-19},
	journal = {Atmospheric Environment},
	author = {Gupta, Pawan and Christopher, Sundar A. and Wang, Jun and Gehrig, Robert and Lee, Yc and Kumar, Naresh},
	month = sep,
	year = {2006},
	keywords = {Aerosols, Air quality, Mega cities, Satellite remote sensing},
	pages = {5880--5892},
}

@article{rao_role_2006,
	title = {The {Role} of {Non}-{CO2} {Greenhouse} {Gases} in {Climate} {Change} {Mitigation}: {Long}-term {Scenarios} for the 21st {Century}},
	volume = {SI2006},
	issn = {01956574},
	shorttitle = {The {Role} of {Non}-{CO2} {Greenhouse} {Gases} in {Climate} {Change} {Mitigation}},
	url = {http://www.iaee.org/en/publications/ejarticle.aspx?id=2191},
	doi = {10.5547/ISSN0195-6574-EJ-VolSI2006-NoSI3-9},
	number = {01},
	urldate = {2021-09-19},
	journal = {The Energy Journal},
	author = {Rao, Shilpa and Riahi, Keywan},
	month = sep,
	year = {2006},
}

@misc{noauthor_air_nodate-3,
	title = {Air pollution},
	url = {https://www.who.int/westernpacific/health-topics/air-pollution},
	abstract = {Air pollution kills an estimated seven million people worldwide every year. WHO data shows that 9 out of 10 people breathe air containing high levels of pollutants. WHO is working with countries to monitor air pollution and improve air quality.},
	language = {en},
	urldate = {2021-09-19},
}

@article{huang_densely_2018,
	title = {Densely {Connected} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1608.06993},
	abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet .},
	urldate = {2021-09-19},
	journal = {arXiv:1608.06993 [cs]},
	author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
	month = jan,
	year = {2018},
	note = {arXiv: 1608.06993},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{he_deep_2015-1,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2021-09-19},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{wang_deep_2020,
	title = {Deep {High}-{Resolution} {Representation} {Learning} for {Visual} {Recognition}},
	url = {http://arxiv.org/abs/1908.07919},
	abstract = {High-resolution representations are essential for position-sensitive vision problems, such as human pose estimation, semantic segmentation, and object detection. Existing state-of-the-art frameworks first encode the input image as a low-resolution representation through a subnetwork that is formed by connecting high-to-low resolution convolutions {\textbackslash}emph\{in series\} (e.g., ResNet, VGGNet), and then recover the high-resolution representation from the encoded low-resolution representation. Instead, our proposed network, named as High-Resolution Network (HRNet), maintains high-resolution representations through the whole process. There are two key characteristics: (i) Connect the high-to-low resolution convolution streams {\textbackslash}emph\{in parallel\}; (ii) Repeatedly exchange the information across resolutions. The benefit is that the resulting representation is semantically richer and spatially more precise. We show the superiority of the proposed HRNet in a wide range of applications, including human pose estimation, semantic segmentation, and object detection, suggesting that the HRNet is a stronger backbone for computer vision problems. All the codes are available at{\textasciitilde}\{{\textbackslash}url\{https://github.com/HRNet\}\}.},
	urldate = {2021-09-19},
	journal = {arXiv:1908.07919 [cs]},
	author = {Wang, Jingdong and Sun, Ke and Cheng, Tianheng and Jiang, Borui and Deng, Chaorui and Zhao, Yang and Liu, Dong and Mu, Yadong and Tan, Mingkui and Wang, Xinggang and Liu, Wenyu and Xiao, Bin},
	month = mar,
	year = {2020},
	note = {arXiv: 1908.07919},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{lamba_understanding_2019,
	title = {Understanding {Semantic} {Segmentation} with {UNET}},
	url = {https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47},
	abstract = {A Salt Identification Case Study},
	language = {en},
	urldate = {2021-09-19},
	journal = {Medium},
	author = {Lamba, Harshall},
	month = feb,
	year = {2019},
}

@misc{noauthor_air_nodate-4,
	title = {Air {Quality}},
	url = {https://www.google.com/earth/outreach/special-projects/air-quality/},
	abstract = {Making the invisible visible with Project Air View},
	language = {en},
	urldate = {2021-09-19},
}

@article{whitehill_uncertainty_2020-1,
	title = {Uncertainty in collocated mobile measurements of air quality},
	volume = {7},
	issn = {2590-1621},
	doi = {10.1016/j.aeaoa.2020.100080},
	abstract = {Mobile mapping of air pollution has the potential to provide pollutant concentration data at unprecedented spatial scales. Characterizing instrument performance in the mobile context is challenging, but necessary to analyze and interpret the resulting data. We used robust statistical methods to assess mobile platform performance using data collected with the Aclima Inc. mobile air pollution measurement and data acquisition platform installed on three Google Street View cars. They were driven throughout the greater Denver metropolitan area between July 25, 2014 and August 14, 2014, measuring ozone (O3), nitrogen dioxide (NO2), nitric oxide (NO), black carbon (BC), and size-resolve particle number counts (PN) between 0.3 μm and 5.0 μm diameter. August 6, 2014 was dedicated to parked and moving collocations among the three cars, allowing an assessment of measurement precision and bias. We used the median absolute deviation (MAD) to estimate instrument precision from outdoor, parked collocations. Bias was assessed by measurements obtained from parked cars using the standard deviation of median values over a collocated measurement period, as well as by Passing-Bablok regression statistics while the cars were moving and collocated. For the moving collocation periods, we compared the distribution of 1-σ standard deviations among the 3 cars to the estimated distribution assuming only measurement uncertainty (precision and bias). The distribution of mobile measurements agreed well with the theoretical uncertainty distribution at the lower end of the distribution for O3, NO2, and PN. We assert that the difference between the actual and theoretical distributions is due to real spatial variability between pollutants. The agreement between the parked car estimates of uncertainty and that measured during the mobile collocations (at the lower quantiles) provides evidence that on-road collocation while parked could be sufficient for estimating measurement uncertainties of a mobile platform, even when extended to the moving environment.},
	language = {eng},
	journal = {Atmospheric Environment: X},
	author = {Whitehill, Andrew R. and Lunden, Melissa and Kaushik, Surender and Solomon, Paul},
	month = oct,
	year = {2020},
	pmid = {33748742},
	pmcid = {PMC7970519},
	keywords = {Black carbon Ozone, Coefficient of variation, Median absolute deviation, Mobile monitoring, Nitric oxide, Nitrogen dioxide, Particulate matter},
}

@article{carvalho_air_2016,
	title = {The air we breathe: differentials in global air quality monitoring},
	volume = {4},
	issn = {2213-2619},
	shorttitle = {The air we breathe},
	doi = {10.1016/S2213-2600(16)30180-1},
	language = {eng},
	number = {8},
	journal = {The Lancet. Respiratory Medicine},
	author = {Carvalho, Helotonio},
	month = aug,
	year = {2016},
	pmid = {27423918},
	keywords = {Air Pollutants, Air Pollution, Environmental Exposure, Environmental Monitoring, Female, Global Health, Humans, Internationality, Male, Public Health, Respiration, World Health Organization},
	pages = {603--605},
}

@article{brauer_ambient_2016,
	title = {Ambient {Air} {Pollution} {Exposure} {Estimation} for the {Global} {Burden} of {Disease} 2013},
	volume = {50},
	issn = {0013-936X},
	url = {https://doi.org/10.1021/acs.est.5b03709},
	doi = {10.1021/acs.est.5b03709},
	abstract = {Exposure to ambient air pollution is a major risk factor for global disease. Assessment of the impacts of air pollution on population health and evaluation of trends relative to other major risk factors requires regularly updated, accurate, spatially resolved exposure estimates. We combined satellite-based estimates, chemical transport model simulations, and ground measurements from 79 different countries to produce global estimates of annual average fine particle (PM2.5) and ozone concentrations at 0.1° × 0.1° spatial resolution for five-year intervals from 1990 to 2010 and the year 2013. These estimates were applied to assess population-weighted mean concentrations for 1990–2013 for each of 188 countries. In 2013, 87\% of the world’s population lived in areas exceeding the World Health Organization Air Quality Guideline of 10 μg/m3 PM2.5 (annual average). Between 1990 and 2013, global population-weighted PM2.5 increased by 20.4\% driven by trends in South Asia, Southeast Asia, and China. Decreases in population-weighted mean concentrations of PM2.5 were evident in most high income countries. Population-weighted mean concentrations of ozone increased globally by 8.9\% from 1990–2013 with increases in most countries—except for modest decreases in North America, parts of Europe, and several countries in Southeast Asia.},
	number = {1},
	urldate = {2021-09-19},
	journal = {Environmental Science \& Technology},
	author = {Brauer, Michael and Freedman, Greg and Frostad, Joseph and van Donkelaar, Aaron and Martin, Randall V. and Dentener, Frank and Dingenen, Rita van and Estep, Kara and Amini, Heresh and Apte, Joshua S. and Balakrishnan, Kalpana and Barregard, Lars and Broday, David and Feigin, Valery and Ghosh, Santu and Hopke, Philip K. and Knibbs, Luke D. and Kokubo, Yoshihiro and Liu, Yang and Ma, Stefan and Morawska, Lidia and Sangrador, José Luis Texcalac and Shaddick, Gavin and Anderson, H. Ross and Vos, Theo and Forouzanfar, Mohammad H. and Burnett, Richard T. and Cohen, Aaron},
	month = jan,
	year = {2016},
	note = {Publisher: American Chemical Society},
	pages = {79--88},
}

@article{berezin_multiannual_2013,
	title = {Multiannual changes of {CO}$_{\textrm{2}}$ emissions in {China}: indirect estimates derived from satellite measurements of tropospheric {NO}$_{\textrm{2}}$ columns},
	volume = {13},
	issn = {1680-7316},
	shorttitle = {Multiannual changes of {CO}$_{\textrm{2}}$ emissions in {China}},
	url = {https://acp.copernicus.org/articles/13/9415/2013/},
	doi = {10.5194/acp-13-9415-2013},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} Multiannual satellite measurements of tropospheric NO$_{\textrm{2}}$ columns are used for evaluation of CO$_{\textrm{2}}$ emission changes in China in the period from 1996 to 2008. Indirect top-down annual estimates of CO$_{\textrm{2}}$ emissions are derived from the satellite NO$_{\textrm{2}}$ column measurements by means of a simple inverse modeling procedure involving simulations performed with the CHIMERE mesoscale chemistry–transport model and the CO$_{\textrm{2}}$-to-NO$_{\textrm{x}}$ emission ratios from the Emission Database for Global Atmospheric Research (EDGAR) global anthropogenic emission inventory and Regional Emission Inventory in Asia (REAS). Exponential trends in the normalized time series of annual emissions are evaluated separately for the periods from 1996 to 2001 and from 2001 to 2008. The results indicate that the both periods manifest strong positive trends in the CO$_{\textrm{2}}$ emissions, and that the trend in the second period was significantly larger than the trend in the first period. Specifically, the trends in the first and second periods are best estimated to be in the range from 3.7 to 8.3 and from 11.0 to 13.2\% per year, respectively, taking into account statistical uncertainties and differences between the CO$_{\textrm{2}}$-to-NO$_{\textrm{x}}$ emission ratios from the EDGAR and REAS inventories. Comparison of our indirect top-down estimates of the CO$_{\textrm{2}}$ emission changes with the corresponding bottom-up estimates provided by the EDGAR (version 4.2) and Global Carbon Project (GCP) glomal emission inventories reveals that while acceleration of the CO$_{\textrm{2}}$ emission growth in the considered period is a common feature of both kinds of estimates, nonlinearity in the CO$_{\textrm{2}}$ emission changes may be strongly exaggerated in the global emission inventories. Specifically, the atmospheric NO$_{\textrm{2}}$ observations do not confirm the existence of a sharp bend in the emission inventory data time series in the period from 2000 to 2002. A significant quantitative difference is revealed between the bottom-up and indirect top-down estimates of the CO$_{\textrm{2}}$ emission trend in the period from 1996 to 2001 (specifically, the trend was not positive according to the global emission inventories, but is strongly positive in our estimates). These results confirm the findings of earlier studies that indicated probable large uncertainties in the energy production and other activity data for China from international energy statistics used as the input information in the global emission inventories. For the period from 2001 to 2008, some quantitative differences between the different kinds of estimates are found to be in the range of possible systematic uncertainties associated with our estimation method. In general, satellite measurements of tropospheric NO$_{\textrm{2}}$ are shown to be a useful source of information on CO$_{\textrm{2}}$ sources collocated with sources of nitrogen oxides; the corresponding potential of these measurements should be exploited further in future studies.{\textless}/p{\textgreater}},
	language = {English},
	number = {18},
	urldate = {2021-09-19},
	journal = {Atmospheric Chemistry and Physics},
	author = {Berezin, E. V. and Konovalov, I. B. and Ciais, P. and Richter, A. and Tao, S. and Janssens-Maenhout, G. and Beekmann, M. and Schulze, E.-D.},
	month = sep,
	year = {2013},
	note = {Publisher: Copernicus GmbH},
	pages = {9415--9438},
}

@article{pope_health_2006,
	title = {Health effects of fine particulate air pollution: lines that connect},
	volume = {56},
	issn = {1096-2247},
	shorttitle = {Health effects of fine particulate air pollution},
	doi = {10.1080/10473289.2006.10464485},
	abstract = {Efforts to understand and mitigate thehealth effects of particulate matter (PM) air pollutionhave a rich and interesting history. This review focuseson six substantial lines of research that have been pursued since 1997 that have helped elucidate our understanding about the effects of PM on human health. There hasbeen substantial progress in the evaluation of PM health effects at different time-scales of exposure and in the exploration of the shape of the concentration-response function. There has also been emerging evidence of PM-related cardiovascular health effects and growing knowledge regarding interconnected general pathophysiological pathways that link PM exposure with cardiopulmonary morbidiity and mortality. Despite important gaps in scientific knowledge and continued reasons for some skepticism, a comprehensive evaluation of the research findings provides persuasive evidence that exposure to fine particulate air pollution has adverse effects on cardiopulmonaryhealth. Although much of this research has been motivated by environmental public health policy, these results have important scientific, medical, and public health implications that are broader than debates over legally mandated air quality standards.},
	language = {eng},
	number = {6},
	journal = {Journal of the Air \& Waste Management Association (1995)},
	author = {Pope, C. Arden and Dockery, Douglas W.},
	month = jun,
	year = {2006},
	pmid = {16805397},
	keywords = {Air Pollution, Animals, Cardiovascular Diseases, Dust, Epidemiologic Studies, Humans, Meta-Analysis as Topic, Particle Size},
	pages = {709--742},
}

@misc{noauthor_addressing_nodate,
	title = {Addressing {Global} {Mortality} from {Ambient} {PM2}.5 {\textbar} {Environmental} {Science} \& {Technology}},
	url = {https://pubs.acs.org/doi/10.1021/acs.est.5b01236},
	urldate = {2021-09-19},
}

@article{scheibenreif_estimation_nodate,
	title = {Estimation of {Air} {Pollution} with {Remote} {Sensing} {Data}:  {Revealing} {Greenhouse} {Gas} {Emissions} from {Space}},
	abstract = {Air pollution is a major driver of climate change. Anthropogenic emissions from the burning of fossil fuels for transportation and power generation emit large amounts of problematic air pollutants, including Greenhouse Gases (GHGs). Despite the importance of limiting GHG emissions to mitigate climate change, detailed information about the spatial and temporal distribution of GHG and other air pollutants is difﬁcult to obtain. Existing models for surface-level air pollution rely on extensive land-use datasets which are often locally restricted and temporally static. This work proposes a deep learning approach for the prediction of ambient air pollution that only relies on remote sensing data that is globally available and frequently updated. Combining optical satellite imagery with satellite-based atmospheric column density air pollution measurements enables the scaling of air pollution estimates (in this case NO2) to high spatial resolution (up to ∼10m) at arbitrary locations and adds a temporal component to these estimates. The proposed model performs with high accuracy when evaluated against air quality measurements from ground stations (mean absolute error {\textless}6 µg/m3). Our results enable the identiﬁcation and temporal monitoring of major sources of air pollution and GHGs.},
	language = {en},
	author = {Scheibenreif, Linus and Mommert, Michael and Borth, Damian},
	pages = {7},
}
